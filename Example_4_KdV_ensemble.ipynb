{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "from ml_collections import ConfigDict\n",
    "from models.ETD_KT_CM_JAX_Vectorised import *\n",
    "from filters import resamplers\n",
    "from filters.filter import ParticleFilter\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "import metrics.ensemble as ens_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advection_basis_name: constant\n",
      "E: 10\n",
      "Forcing_basis_name: none\n",
      "P: 1\n",
      "S: 0\n",
      "c_0: 0\n",
      "c_1: 1\n",
      "c_2: 0.0\n",
      "c_3: 2.0e-05\n",
      "c_4: 0.0\n",
      "dt: 0.001\n",
      "equation_name: KdV\n",
      "initial_condition: gaussian\n",
      "method: Dealiased_SETDRK4\n",
      "noise_magnitude: 0.01\n",
      "nx: 256\n",
      "tmax: 1\n",
      "xmax: 1\n",
      "xmin: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "signal_params = ConfigDict(KDV_params_2_SALT)\n",
    "ensemble_params = ConfigDict(KDV_params_2_SALT)\n",
    "print(signal_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we specify a signal, by choosing a deterministic solver, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_params.update(E=1,nx = 256,P=1,S=0,tmax=1)\n",
    "ensemble_params.update(E=128,noise_magnitude=0.01,P=1,tmax=1)\n",
    "n_filter_steps = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we continue to define a stochastic ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify the models, by calling the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739281101.943926       1 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ETD_KT_CM_JAX_Vectorised' object has no attribute 'nmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m signal_model \u001b[38;5;241m=\u001b[39m \u001b[43mETD_KT_CM_JAX_Vectorised\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m ensemble_model \u001b[38;5;241m=\u001b[39m ETD_KT_CM_JAX_Vectorised(ensemble_params)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Particle_Filter/models/ETD_KT_CM_JAX_Vectorised.py:35\u001b[0m, in \u001b[0;36mETD_KT_CM_JAX_Vectorised.__init__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mE_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mE_2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf3 \u001b[38;5;241m=\u001b[39m Kassam_Trefethen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mdt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mnx)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#self.nmax = round(self.params.tmax / self.params.dt)\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mtmax\u001b[38;5;241m/\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnmax\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey2 \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnoise_key)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ETD_KT_CM_JAX_Vectorised' object has no attribute 'nmax'"
     ]
    }
   ],
   "source": [
    "signal_model = ETD_KT_CM_JAX_Vectorised(signal_params)\n",
    "ensemble_model = ETD_KT_CM_JAX_Vectorised(ensemble_params)\n",
    "\n",
    "import numpy as np\n",
    "initial_signal = initial_condition(signal_model.x, signal_params.E, signal_params.initial_condition)\n",
    "initial_ensemble = initial_condition(ensemble_model.x, ensemble_params.E, ensemble_params.initial_condition)\n",
    "\n",
    "available_resamplers = \", \".join(resamplers.keys())\n",
    "print(available_resamplers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_frequency = 32\n",
    "observation_noise = 1e-4\n",
    "observation_locations_params = jnp.arange(0,len(signal_model.x),obs_frequency)\n",
    "data_assimilation_freq = 16\n",
    "n_filter_steps = int(signal_model.nmax//data_assimilation_freq)\n",
    "\n",
    "pf_systematic = ParticleFilter(\n",
    "    n_particles = ensemble_params.E,\n",
    "    n_steps = data_assimilation_freq,\n",
    "    n_dim = initial_signal.shape[-1],\n",
    "    forward_model = ensemble_model,\n",
    "    signal_model = signal_model,\n",
    "    sigma = observation_noise,\n",
    "    seed = 11,\n",
    "    resampling='multinomial',\n",
    "    observation_locations = np.arange(0,signal_model.x.shape[0],128),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that the last input is not the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "final, all = pf_systematic.run(initial_ensemble, initial_signal, n_filter_steps) #the final input is scan length? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put in the initial condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particles Shape: (63, 128, 256) is (N_da_steps+1, N_particles, N_dim)\n",
      "Signal Shape: (63, 1, 256) is (N_da_steps+1, 1,  N_dim)\n",
      "3\n",
      "Observations Shape: (62, 1, 256) is (N_da_steps, 1,  N_dim)\n"
     ]
    }
   ],
   "source": [
    "particles =jnp.concatenate([initial_ensemble[None,...], all[0]], axis=0)\n",
    "signal = jnp.concatenate([initial_signal[None,...], all[1]], axis=0)\n",
    "print(f\"Particles Shape: {particles.shape} is (N_da_steps+1, N_particles, N_dim)\")\n",
    "print(f\"Signal Shape: {signal.shape} is (N_da_steps+1, 1,  N_dim)\")\n",
    "print(len(all))\n",
    "observations = all[2]\n",
    "print(f\"Observations Shape: {observations.shape} is (N_da_steps, 1,  N_dim)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d00fe04a3141d18c44cc5cda3b484b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='da_step', max=62), Output()), _dom_classes=('widget-intâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot(da_step)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot(da_step):\n",
    "    plt.plot(signal_model.x, signal[da_step,0,:], color='k',label='signal')\n",
    "    plt.plot(signal_model.x, particles[da_step,:,:].T, color='b',label='particles',linewidth=0.1)\n",
    "    plt.show()\n",
    "\n",
    "interact(plot, da_step=(0, n_filter_steps))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Particle_Filter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
